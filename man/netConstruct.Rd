% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/netConstruct.R
\name{netConstruct}
\alias{netConstruct}
\title{Constructing Networks for Microbiome Data}
\usage{
netConstruct(
  data,
  data2 = NULL,
  dataType = "counts",
  group = NULL,
  measure = "spieceasi",
  measurePar = NULL,
  filtTax = "none",
  filtTaxPar = NULL,
  filtSamp = "none",
  filtSampPar = NULL,
  zeroMethod = "none",
  zeroPar = NULL,
  normMethod = "none",
  normPar = NULL,
  sparsMethod = "t-test",
  thresh = 0.3,
  alpha = 0.05,
  adjust = "adaptBH",
  trueNullMethod = "convest",
  lfdrThresh = 0.2,
  nboot = 1000L,
  cores = 1L,
  logFile = "log.txt",
  softThreshType = "signed",
  softThreshPower = NULL,
  softThreshCut = 0.8,
  kNeighbor = 3L,
  knnMutual = FALSE,
  dissFunc = "signed",
  dissFuncPar = NULL,
  simFunc = NULL,
  simFuncPar = NULL,
  scaleDiss = TRUE,
  weighted = TRUE,
  sampleSize = NULL,
  verbose = 2,
  seed = NULL
)
}
\arguments{
\item{data}{numeric matrix. Can be a count matrix (rows are samples, columns
are OTUs/taxa), a phyloseq object, or an association/dissimilarity matrix
(\code{dataType} must be set).}

\item{data2}{optional numeric matrix corresponding to group 2. Can be either
a second count matrix/phyloseq object or a second association/dissimilarity
matrix.}

\item{dataType}{character indicating the data type. Defaults to "counts",
which means that \code{data} (and data2) is a count matrix or object of
class \code{\link[phyloseq:phyloseq-class]{phyloseq}}. Further options
are "correlation", "partialCorr" (partial correlation), "condDependence"
(conditional dependence), "proportionality" and "dissimilarity".}

\item{group}{optional binary vector used or splitting the data into two
groups. If \code{group} is \code{NULL} (default), a single network is
constructed. See details.}

\item{measure}{character specifying the method used for either computing the
associations between taxa or dissimilarities between subjects.
Ignored if \code{data} is not a count matrix (if \code{dataType} is not set
to \code{"counts"}). Available measures are:
\code{"pearson"}, \code{"spearman"}, \code{"bicor"}, \code{"sparcc"},
\code{"cclasso"}, \code{"ccrepe"}, \code{"spieceasi"} (default),
\code{"spring"}, \code{"gcoda"} and \code{"propr"} as association measures,
and \code{"euclidean"}, \code{"bray"}, \code{"kld"}, \code{"jeffrey"},
\code{"jsd"}, \code{"ckld"}, and \code{"aitchison"} as dissimilarity
measures. Parameters are set via \code{measurePar}.}

\item{measurePar}{list with parameters passed to the function for computing
associations/dissimilarities. See details for the respective functions.}

\item{filtTax}{character indicating how taxa shall be filtered. Possible
options are:
\describe{
\item{\code{"none"}}{Default. All taxa are kept.}
\item{\code{"totalReads"}}{Keep taxa with a total number
of reads of at least x.}
\item{\code{"relFreq"}}{Keep taxa whose number of reads is at
least x\% of the total number of reads.}
\item{\code{"numbSamp"}}{Keep taxa observed in at least x samples.}
\item{\code{"highestVar"}}{Keep the x taxa with highest variance.}
\item{\code{"highestFreq"}}{Keep the x taxa with highest frequency.}}
Except for "highestVar" and "highestFreq", different filter methods can be
combined. The values x are set via \code{filtTaxPar}.}

\item{filtTaxPar}{list with parameters for the filter methods given by
\code{filtTax}. Possible list entries are: \code{"totalReads"} (int),
\code{"relFreq"} (value in [0,1]), \code{"numbSamp"} (int),
\code{"highestVar"} (int), \code{"highestFreq"} (int).}

\item{filtSamp}{character indicating how samples shall be filtered. Possible
options are: \describe{
\item{\code{"none"}}{Default. All samples are kept.}
\item{\code{"totalReads"}}{Keep samples with a total number of reads of at
least x.}
\item{\code{"numbTaxa"}}{Keep samples for which at least
x taxa are observed.}
\item{\code{"highestFreq"}}{Keep the x samples with highest frequency.}}
Except for "highestFreq", different filter methods can be
combined. The values x are set via \code{filtSampPar}.}

\item{filtSampPar}{list with parameters for the filter methods given by
\code{filtSamp}. Possible list entries are: \code{"totalReads"} (int),
\code{"numbTaxa"} (int), \code{"highestFreq"} (int).}

\item{zeroMethod}{character indicating the method used for zero replacement.
Possible values are: \code{"none"} (default), \code{"pseudo"}
(a unit pseudo count is added to the original count data),
\code{"multRepl"} (multiplicative replacement using
\code{\link[zCompositions]{multRepl}}), \code{"alrEM"} (modified EM
alr-algorithm using \code{\link[zCompositions]{lrEM}}), \code{"bayesMult"}
(Bayesian-multiplicative replacement using
\code{\link[zCompositions]{cmultRepl}}). The corresponding parameters are
set via \code{zeroPar}. \code{zeroMethod} is ignored if the approach for
calculating the associations/dissimilarity includes zero handling.
Defaults to \code{"multRepl"} or \code{"pseudo"} (depending on the expected
input of the normalization function and measure) if zero replacement is
required.}

\item{zeroPar}{list with parameters passed to the function for zero
replacement (\code{zeroMethod}). See the help page of the respective
function for details.}

\item{normMethod}{character indicating the normalization method (in order to
make counts of different samples comparable). Possible options are:
\code{"none"} (default), \code{"TSS"} (or \code{"fractions"}), \code{"CSS"},
\code{"COM"}, \code{"rarefy"}, \code{"VST"}, \code{"clr"}.
The corresponding parameters are set via \code{normPar}.}

\item{normPar}{list with parameters passed to the function for normalization
(defined by \code{normMethod}).}

\item{sparsMethod}{character indicating the method used for sparsification
(selected edges that are connected in the network). Available methods are:
\describe{
\item{\code{"none"}}{Leads to a fully connected network}
\item{\code{"t-test"}}{Student's t-test. Significance level and multiple
testing adjustment is specified via \code{alpha} and \code{adjust}.}
\item{\code{"bootstrap"}}{Bootstrap procedure as described in
\cite{Friedman and Alm (2012)}. Corresponding arguments are
\code{nboot}, \code{cores}, and \code{logFile}.}
\item{\code{"threshold"}}{Default. Selected are taxa
pairs with an absolute association/dissimilarity greater than or equal to
the threshold defined via \code{thresh}.}
\item{\code{"softThreshold"}}{Soft thresholding method according to
\cite{Zhang and Horvath (2005)} available in the
\code{\link[WGCNA:pickSoftThreshold]{WGCNA}} package. Corresponding
arguments are \code{softThreshType}, \code{softThreshPower}, and
\code{softThreshCut}.}
\item{\code{"knn"}}{Construct a k-nearest neighbor or mutual k-nearest
neighbor graph using \code{\link[cccd]{nng}}. Corresponding
arguments are \code{kNeighbor}, and \code{knnMutual}.}}}

\item{thresh}{numeric value defining the threshold if \code{sparsMethod} is
set to \code{"threshold"}. Defaults to 0.3.}

\item{alpha}{significance niveau. Only used if Student's t-test or bootstrap
procedure is used as sparsification method. Defaults to 0.05.}

\item{adjust}{character indicating the method used for multiple testing
adjustment (if tudent's t-test or bootstrap procedure is used for edge
selection). Possible values are \code{"lfdr"} (default) for local
false discovery rate correction (via \code{\link[fdrtool]{fdrtool}}),
\code{"adaptBH"} for the adaptive Benjamini-Hochberg method
\cite{(Benjamini and Hochberg, 2000)}, or one of the methods provided by
\code{\link[stats]{p.adjust}} (see \code{p.adjust.methods()}.}

\item{trueNullMethod}{character indicating the method used for estimating the
proportion of true null hypotheses from a vector of p-values. Used for the
adaptive Benjamini-Hochberg method for multiple testing adjustment (chosen
by \code{adjust = "adaptBH"}). Accepts the provided options of the
\code{method} argument of \code{\link[limma]{propTrueNull}}:
\code{"convest"}(default), \code{"lfdr"}, \code{"mean"}, and \code{"hist"}.
Can alternatively be \code{"farco"} for
the "iterative plug-in method" proposed by \cite{Farcomeni (2007)}.}

\item{lfdrThresh}{threshold for local FDR (if \code{adjust} is set to
\code{"locfdr"}). Defaults to 0.2 meaning that associations with a
corresponding local FDR less than or equal to 0.2 are identified as
significant.}

\item{nboot}{integer indicating the number of bootstrap samples, if
bootstrappng is used as sparsification method.}

\item{cores}{integer indicating the number of CPU cores used for
bootstrapping. If cores > 1, bootstrapping is performed parallel.
\code{cores} is limited to the number of available CPU cores determined by
\code{\link[parallel]{detectCores}}. Then, core arguments of the function 
used for association estimation (if provided) should be set to 1.}

\item{logFile}{if bootstrapping is used as sparsification method, a log file
containing the iteration numbers is stored into the current working
directory. Defaults to \code{"log.txt"}. If\code{ NULL}, no log file is
created.}

\item{softThreshType}{character indicating the method used for transforming
correlations to similarities if soft thresholding is used as sparsification
method (\code{sparsMethod = "softThreshold"}). Possible values are
\code{"signed"}, \code{"unsigned"}, and \code{"signed hybrid"} (according
to the available options for the argument \code{type} of
\code{\link[WGCNA]{adjacency}} from \code{WGCNA} package).}

\item{softThreshPower}{power for soft thresholding. Only used if
\code{edgeSelect} is set to \code{"softThreshold"}. Expects either a single
numeric value (used for a single or both networks) or a vector with two
values (one for each network). If no power is set, it is computed using
\code{\link[WGCNA]{pickSoftThreshold}}, where the argument
\code{softThreshCut} is needed in addition.}

\item{softThreshCut}{numeric value between 0 and 1 indicating the desired
minimum scale free topology fitting index (corresponds to the argument
"RsquaredCut" in \code{\link[WGCNA]{pickSoftThreshold}}). Defaults to 0.8.}

\item{kNeighbor}{integer specifying the number of neighbors if the k-nearest
neighbor method is used for sparsification.}

\item{knnMutual}{logical used for k-nearest neigbor sparsification. If
\code{TRUE}, the neighbors must be mutual.}

\item{dissFunc}{method used for transforming associations to dissimilarities.
Can be a character with one of the following values: \code{"signed"}
(default), \code{"unsigned"}, \code{"signedPos"}, \code{"TOMdiss"}.
Alternatively, a function is accepted with the association matrix as first
argument and optional further arguments, which can be set viel
\code{dissFuncPar}. Ignored for dissimilarity measures. See details.}

\item{dissFuncPar}{optional list with parameters if a function is passed to
\code{dissFunc}.}

\item{simFunc}{alternative function for transforming dissimilarities to
similarities. Defaults to f(x)=1-x for dissimilarities in [0,1], and
f(x)=1/(1 + x) otherwise.}

\item{simFuncPar}{optional list with parameters for the function passed to
\code{simFunc}.}

\item{scaleDiss}{logical. Indicates whether dissimilarity values should be
scaled to [0,1] by (x - min(dissEst)) / (max(dissEst) - min(dissEst)),
where dissEst is the matrix with estimated dissimilarities.
Defaults to \code{TRUE}.}

\item{weighted}{logical. If \code{TRUE}, similarity values are used as
adjacencies. \code{FALSE} leads to a binary adjacency matrix whose entries
equal 1 for (sparsified) similarity values > 0, and 0 otherwise.}

\item{sampleSize}{integer giving the number of samples that have been used
for computing the association matrix. Only needed if an association matrix
is given instead of a count matrix and if, in addition, Student's t-test is
used for edge selection.}

\item{verbose}{integer indicating the level of verbosity. Possible values:
\code{"0"}: no messages, \code{"1"}: only important messages shown,
\code{"2"}(default): all progress messages shown, \code{"3"} messages
returned from external functions are shown in addition. Can also be logical.}

\item{seed}{integer giving a seed for reproducibility of the results.}
}
\value{
An object of class \code{microNet} containing the following elements:
  \tabular{ll}{
  \code{assoMat1, assoMat2}\tab Sparsified associations (\code{NULL} for
  dissimlarity based networks)\cr
  \code{dissMat1, dissMat2}\tab Sparsified dissimilarities (for association
  networks, these are the sparsified associations transformed to
  dissimilarities)\cr
  \code{simMat1, simMat2}\tab Sparsified similarities\cr
  \code{adjamat1, adjamat2}\tab Adjacency matrices\cr
  \code{assoEst1, assoEst2}\tab Estimated associations (\code{NULL} for
  dissimlarity based networks)\cr
  \code{dissEst1, dissEst2}\tab Estimated dissimilarities (\code{NULL} for
  association networks)\cr
  \code{dissScale1, dissScale2}\tab Scaled dissimilarities (\code{NULL} for
  association networks)\cr
  \code{countMat1, countMat2}\tab Count matrices, where taxa and samples are
  filtered according to \code{filtTax} and \code{filtSamp}\cr
  \code{normCounts1, normCounts2}\tab Counts that are normalized according to
  \code{normMethod}\cr
  \code{groups}\tab Names of the factor levels according to which the groups
  have been built\cr
  \code{softThreshPower}\tab Determined (or given) power for
  soft-thresholding.\cr
  \code{assoType}\tab Data type (either given by \code{dataType} or
  determined from \code{measure})\cr
  \code{twoNets}\tab Indicates whether two networks have been constructed\cr
  \code{parameters}\tab Parameters used for network construction}
}
\description{
Constructing microbial association networks and dissimilarity
  based networks (where nodes are subjects) from compositional count data.
}
\details{
The function enables the construction of either a single network or
  two networks that can be compared using the function
  \code{\link{netCompare}}. Four types of association  measures are
  available: correlation, conditional dependence, proportionality, and
  dissimilarity.  Depending on the measure, nodes are either taxa or subjects
  in the resulting network: In association-based networks (correlation,
  partial correlation, conditional dependence, proportionality) nodes are
  taxa, whereas in dissimilarity-based networks nodes are subjects.\cr\cr
  In order to conduct a network comparison, two networks can be  constructed
  by: \tabular{ll}{
  (1)\tab passing a group vector to \code{group} (of length
  \code{nrow(data)} for association networks and of length \code{ncol(data)}
  for dissimilarity-based networks), or\cr
  (2)\tab passing a second count matrix to \code{data2} (column names must
  match for constructing association networks and row names must match for
  dissimilarity-based networks), or \cr
  (3)\tab passing a second association/dissimilarity matrix to \code{data2}.}
  \cr
  The object returned from \code{netConstruct} can either be passed to
  \code{\link{netAnalyze}} for network analysis, or to
  \code{\link{diffnet}} to construct a differential network from the
  estimated associations.\cr\cr
  \strong{Association measures:}
  \tabular{ll}{
  Argument \tab Function\cr
  \code{"pearson"}\tab \code{\link[stats]{cor}} \cr
  \code{"spearman"}\tab \code{\link[stats]{cor}} \cr
  \code{"bicor"}\tab \code{\link[WGCNA]{bicor}} \cr
  \code{"sparcc"}\tab \code{\link[SpiecEasi]{sparcc}} \cr
  \code{"cclasso"}\tab \code{\link[NetCoMi]{cclasso}} \cr
  \code{"ccrepe"}\tab \code{\link[ccrepe]{ccrepe}} \cr
  \code{"spieceasi"}\tab \code{\link[SpiecEasi]{spiec.easi}} \cr
  \code{"spring"}\tab \code{\link[SPRING]{SPRING}} \cr
  \code{"gcoda"}\tab \code{\link[NetCoMi]{gcoda}} \cr
  \code{"propr"}\tab \code{\link[propr]{propr}}}
  \cr
  \strong{Dissimilarity measures:}
  \tabular{lll}{
  Argument \tab Function \tab Measure\cr
  \code{"euclidean"} \tab \code{\link[vegan]{vegdist}} \tab
  Euclidean distance \cr
  \code{"bray"}\tab \code{\link[vegan]{vegdist}} \tab
  Bray-Curtis  dissimilarity \cr
  \code{"kld"}\tab \code{\link[LaplacesDemon]{KLD}} \tab
  Kullback-Leibler divergence \cr
  \code{"jeffrey"}\tab \code{\link[LaplacesDemon]{KLD}} \tab
  Jeffrey divergence\cr
  \code{"jsd"}\tab \code{\link[LaplacesDemon]{KLD}} \tab
  Jensen-Shannon divergence \cr
  \code{"ckld"}\tab \code{\link[base]{log}} \tab
  Compositional Kullback-Leibler divergence \cr
  \code{"aitchison"}\tab \code{\link[vegan]{vegdist}},
  \code{\link[robCompositions]{cenLR}}\tab
  Aitchison distance}
  Definitions:\cr
  \describe{
  \item{Kullback-Leibler divergence:}{Since KLD is not symmetric,
  0.5 * (KLD(p(x)||p(y)) + KLD(p(y)||p(x))) is returned.}
  \item{Jeffrey divergence:}{Jeff = KLD(p(x)||p(y)) + KLD(p(y)||p(x))}
  \item{Jensen-Shannon divergence:}{JSD = 0.5 KLD(P||M) + 0.5 KLD(Q||M),
  where P=p(x), Q=p(y), and M=0.5(P+Q).}
  \item{Compositional Kullback-Leibler divergence:}{cKLD(x,y) =
  p/2 * log(A(x/y) * A(y/x)), where A(x/y) is the arithmetic mean of the
  vector of ratios x/y.}
  \item{Aitchison distance:}{Euclidean distance of the clr-transformed data.}
  }\cr
  \strong{Normalization methods:}
  \tabular{lll}{
  Argument \tab Method \tab Function\cr
  \code{"TSS"} \tab Total sum scaling \tab t(apply(countMat, 1, function(x)
  x/sum(x)))\cr
  \code{"CSS"} \tab Cumulative sum scaling \tab
  \code{\link[metagenomeSeq]{cumNormMat}}\cr
  \code{"COM"} \tab Common sum scaling \tab
  t(apply(countMat, 1, function(x) x * min(rowSums(countMat)) / sum(x)))\cr
  \code{"rarefy"} \tab Rarefying \tab \code{\link[vegan:rarefy]{rrarefy}}\cr
  \code{"VST"} \tab Variance stabilizing transformation\tab
  \code{\link[DESeq2]{varianceStabilizingTransformation}}\cr
  \code{"clr"} \tab Centered log-ratio transformation\tab
  \code{\link[robCompositions]{cenLR}}
  }
  These methods (except rarefying) are described in
  \cite{Badri et al.(2018)}.
  \cr\cr
  \strong{Transforming associations to dissimilarities:}
  \tabular{ll}{
  Argument \tab Function\cr
  \code{"signed"} \tab sqrt(0.5 * (1 - x))\cr
  \code{"unsigned"} \tab sqrt(1 - x^2)\cr
  \code{"signedPos"} \tab  diss <- sqrt(0.5 * (1-x))\cr
    \tab diss[x < 0] <- 0\cr
  \code{"TOMdiss"} \tab \code{\link[WGCNA:TOMsimilarity]{TOMdist}}
  }
}
\examples{
# load data sets from American Gut Project (from SpiecEasi package)
data("amgut1.filt")
data("amgut2.filt.phy")

# network construction:
amgut_net1 <- netConstruct(amgut2.filt.phy, measure = "spieceasi",
                           measurePar = list(method = "mb",
                           pulsar.params = list(rep.num = 10)),
                           filtTax = "highestVar",
                           filtTaxPar = list(highestVar = 50),
                           filtSamp = "totalReads",
                           filtSampPar = list(totalReads = 1000))

amgut_props1 <- netAnalyze(amgut_net1, clustMethod = "cluster_fast_greedy")

plot(amgut_props1)

# constructing two networks according to a random group variable
set.seed(123456)
group <- sample(1:2, nrow(amgut1.filt), replace = TRUE)
amgut_net2 <- netConstruct(amgut1.filt, group = group,
                           measure = "pearson",
                           filtTax = "highestVar",
                           filtTaxPar = list(highestVar = 50),
                           filtSamp = "totalReads",
                           filtSampPar = list(totalReads = 1000),
                           zeroMethod = "multRepl", normMethod = "clr")
amgut_props2 <- netAnalyze(amgut_net2, clustMethod = "cluster_fast_greedy")
plot(amgut_props2)

}
\references{
\insertRef{badri2018normalization}{NetCoMi}\cr
  \insertRef{benjamini2000adaptive}{NetCoMi}\cr
  \insertRef{farcomeni2007some}{NetCoMi}\cr
  \insertRef{friedman2012inferring}{NetCoMi} \cr
  \insertRef{WGCNApackage}{NetCoMi}\cr
  \insertRef{zhang2005general}{NetCoMi}
}
\seealso{
\code{\link{netAnalyze}} for analyzing the constructed
  network(s), \code{\link{netCompare}} for network comparison,
  \code{\link{diffnet}} for constructing differential networks.
}
